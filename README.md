# AI Learning Journey

This repository is a personal collection of code, experiments, and tools I've created while exploring the world of artificial intelligence. It serves as a living document of my learning process, featuring practical implementations of various AI concepts.

## Core Features

This project has evolved to include several key components:

-   **Optimization Algorithms**: Core implementations of Particle Swarm Optimization (PSO) and Genetic Algorithms (GA) designed for continuous and combinatorial problems.
-   **Interactive Benchmark Suite**: A powerful, menu-driven suite to test, compare, and visualize the performance of the implemented algorithms.
-   **AI Tooling & Integrations**: Standalone servers and scripts that leverage AI for practical tasks, like analyzing code repositories or interacting with generative AI APIs.

## Project Structure

The project is organized into several key directories, each with a distinct purpose:

-   **[`src/`](./src/)**: The heart of the project, containing the core application logic. This is where the algorithm implementations ([`model/`](./src/lib/model/)), the interactive benchmark suite ([`benchmark/`](./src/lib/benchmark/)), and UI components live.

-   **[`mcp/`](./mcp/)**: Contains standalone servers built with the `FastMCP` library. These expose AI functionalities as tools that can be called by other applications, such as the [`code_analyzer.py`](./mcp/code_analyzer.py) which can ingest and summarize Git repositories.

-   **[`scripts/`](./scripts/)**: A collection of miscellaneous, one-off scripts for experiments and utility tasks. This includes examples for using the [Google Gemini API](./scripts/ai-google-api.py) and a CLI tool for the `gitingest` library.

-   **`data/`**: (As per project plan) Intended for all non-code assets, such as datasets, images, and outputs generated by the benchmark suite or other experiments.

-   **`doc/`**: (As per project plan) Reserved for documentation, background research, and Jupyter Notebooks used for demonstrations and exploratory analysis.

## Getting Started

This project uses [**`uv`**](https://docs.astral.sh/uv/), a fast Python package installer and resolver.

### Install Dependencies

First, sync the environment to install all required packages listed in [`pyproject.toml`](./pyproject.toml).

```sh
uv sync
```

### Run the Benchmark Suite

To launch the main interactive benchmark application, run the main entry point:

```sh
uv run src/main.py
```

This will open a terminal menu where you can select algorithms (PSO, GA) and tests to run, including convergence analysis and hyperparameter comparisons.

### Setup your own MCP Server!

To configurate them you must add them to your favorite agentic cli. The content of this directory are useful scripts exposed via MCP.

The tools in the [`mcp/`](./mcp/) directory are designed to be run as separate processes. For example, to start the code analyzer server:

```sh
uv run mcp/example.py
```

## License

This project is for educational purposes and is freely available to use, modify, and distribute under the [**MIT License**](./LICENSE).
