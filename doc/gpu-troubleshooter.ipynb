{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ” GPU Troubleshooting and Diagnostics\n",
    "\n",
    "This notebook is designed to diagnose why your NVIDIA GPU isn't accessible through PyTorch and provide step-by-step solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ System and Installation Diagnostics\n",
    "\n",
    "First, let's check your current PyTorch installation and system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.9 (main, Feb 12 2025, 14:52:31) [MSC v.1942 64 bit (AMD64)]\n",
      "Platform: Windows-11-10.0.26100-SP0\n",
      "\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version (PyTorch): 12.1\n",
      "\n",
      "PyTorch build details:\n",
      "\n",
      "Is this a CPU-only build? No\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "# Check if PyTorch is installed and which version\n",
    "try:\n",
    "    import torch\n",
    "    print(\"\\nPyTorch version:\", torch.__version__)\n",
    "    \n",
    "    # Check CUDA availability\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if hasattr(torch.version, 'cuda'):\n",
    "        print(\"CUDA version (PyTorch):\", torch.version.cuda)\n",
    "    else:\n",
    "        print(\"CUDA version: Not found in PyTorch build\")\n",
    "    \n",
    "    # Display PyTorch build information\n",
    "    print(\"\\nPyTorch build details:\")\n",
    "    build_details = torch.__config__.show()\n",
    "    \n",
    "    # Check if this is a CPU-only build\n",
    "    print(\"\\nIs this a CPU-only build?\", \"Yes\" if not hasattr(torch.version, 'cuda') or torch.version.cuda is None else \"No\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Check GPU Hardware\n",
    "\n",
    "Let's check which GPUs are physically present in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting GPUs...\n",
      "\n",
      "GPUs detected:\n",
      "  1. AMD Radeon 780M Graphics\n",
      "  2. NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "NVIDIA GPUs found:\n",
      "  1. NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "NVIDIA Driver Version: 32.0.15.6636\n",
      "\n",
      "AMD GPUs found:\n",
      "  1. AMD Radeon 780M Graphics\n"
     ]
    }
   ],
   "source": [
    "# Check for NVIDIA GPUs using Windows tools\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            gpu_info = subprocess.check_output(\"wmic path win32_VideoController get name\", shell=True).decode().strip().split('\\n')\n",
    "            gpu_info = [line.strip() for line in gpu_info if line.strip() and line.strip() != \"Name\"]\n",
    "            return gpu_info\n",
    "        else:\n",
    "            return [\"Non-Windows platform - can't use wmic\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Error detecting GPUs: {e}\"]\n",
    "\n",
    "# Check NVIDIA driver\n",
    "def get_nvidia_driver_version():\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            driver_info = subprocess.check_output(\"wmic path win32_VideoController where \\\"name like '%NVIDIA%'\\\" get DriverVersion\", shell=True).decode().strip().split('\\n')\n",
    "            driver_version = [line.strip() for line in driver_info if line.strip() and line.strip() != \"DriverVersion\"]\n",
    "            return driver_version[0] if driver_version else \"Not found\"\n",
    "        else:\n",
    "            return \"Non-Windows platform\"\n",
    "    except Exception as e:\n",
    "        return f\"Error detecting NVIDIA driver: {e}\"\n",
    "\n",
    "# Run the diagnostics\n",
    "print(\"Detecting GPUs...\")\n",
    "gpus = get_gpu_info()\n",
    "print(\"\\nGPUs detected:\")\n",
    "for i, gpu in enumerate(gpus):\n",
    "    print(f\"  {i+1}. {gpu}\")\n",
    "\n",
    "# Filter NVIDIA and AMD GPUs\n",
    "nvidia_gpus = [gpu for gpu in gpus if \"NVIDIA\" in gpu or \"GeForce\" in gpu or \"RTX\" in gpu or \"GTX\" in gpu]\n",
    "amd_gpus = [gpu for gpu in gpus if \"AMD\" in gpu or \"Radeon\" in gpu]\n",
    "\n",
    "if nvidia_gpus:\n",
    "    print(\"\\nNVIDIA GPUs found:\")\n",
    "    for i, gpu in enumerate(nvidia_gpus):\n",
    "        print(f\"  {i+1}. {gpu}\")\n",
    "    \n",
    "    # Get NVIDIA driver info\n",
    "    driver_version = get_nvidia_driver_version()\n",
    "    print(f\"\\nNVIDIA Driver Version: {driver_version}\")\n",
    "else:\n",
    "    print(\"\\nNo NVIDIA GPUs detected\")\n",
    "\n",
    "if amd_gpus:\n",
    "    print(\"\\nAMD GPUs found:\")\n",
    "    for i, gpu in enumerate(amd_gpus):\n",
    "        print(f\"  {i+1}. {gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Diagnose PyTorch GPU Issues\n",
    "\n",
    "Let's determine why PyTorch isn't accessing your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created a CUDA tensor!\n",
      "No issues detected with PyTorch GPU support\n",
      "\n",
      "Checking if CUDA is generally available on your system...\n",
      "CUDA is available on your system! nvidia-smi output:\n",
      "Mon Mar 10 22:17:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   63C    P3             13W /   55W |     509MiB /   8188MiB |     18%      Default |\n"
     ]
    }
   ],
   "source": [
    "def check_pytorch_gpu_support():\n",
    "    try:\n",
    "        import torch\n",
    "        issues = []\n",
    "        \n",
    "        # Check 1: Is PyTorch built with CUDA?\n",
    "        has_cuda_build = hasattr(torch.version, 'cuda') and torch.version.cuda is not None\n",
    "        if not has_cuda_build:\n",
    "            issues.append(\"PyTorch installation doesn't include CUDA support\")\n",
    "        \n",
    "        # Check 2: Is CUDA available at runtime?\n",
    "        if not torch.cuda.is_available():\n",
    "            if has_cuda_build:\n",
    "                issues.append(\"PyTorch has CUDA support, but can't access CUDA at runtime\")\n",
    "        \n",
    "        # Check 3: Try to create a CUDA tensor\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                x = torch.ones(1, device='cuda')\n",
    "                print(\"Successfully created a CUDA tensor!\")\n",
    "            except Exception as e:\n",
    "                issues.append(f\"Failed to create CUDA tensor: {e}\")\n",
    "                \n",
    "        return issues\n",
    "    except ImportError:\n",
    "        return [\"PyTorch is not installed\"]\n",
    "\n",
    "# Check if CUDA is generally available on the system\n",
    "def check_system_cuda():\n",
    "    try:\n",
    "        # Try to run nvidia-smi command\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=False)\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        else:\n",
    "            return False, result.stderr\n",
    "    except Exception as e:\n",
    "        return False, f\"Error running nvidia-smi: {e}\"\n",
    "\n",
    "# Run diagnostics\n",
    "issues = check_pytorch_gpu_support()\n",
    "if issues:\n",
    "    print(\"Issues detected with PyTorch GPU support:\")\n",
    "    for i, issue in enumerate(issues):\n",
    "        print(f\"  {i+1}. {issue}\")\n",
    "else:\n",
    "    print(\"No issues detected with PyTorch GPU support\")\n",
    "\n",
    "# Check system CUDA\n",
    "print(\"\\nChecking if CUDA is generally available on your system...\")\n",
    "cuda_available, cuda_output = check_system_cuda()\n",
    "if cuda_available:\n",
    "    print(\"CUDA is available on your system! nvidia-smi output:\")\n",
    "    print(\"\\n\".join(cuda_output.split('\\n')[:10])) # Show first 10 lines only\n",
    "else:\n",
    "    print(f\"CUDA is not generally available on your system: {cuda_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Verify PyTorch Installation Source\n",
    "\n",
    "Let's check how PyTorch was installed to determine if it's the CUDA version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking PyTorch installation details...\n",
      "PyTorch is installed at: c:\\Users\\fire\\Documents\\Code\\python\\ai\\.venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "PyTorch package version: 2.5.1+cu121\n",
      "Package location: c:\\users\\fire\\documents\\code\\python\\ai\\.venv\\lib\\site-packages\n",
      "This appears to be a CUDA-enabled build of PyTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fire\\AppData\\Local\\Temp\\ipykernel_35776\\3853135887.py:11: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "def check_install_source():\n",
    "    try:\n",
    "        # Get the location of PyTorch\n",
    "        import torch\n",
    "        import inspect\n",
    "        torch_location = inspect.getfile(torch)\n",
    "        print(f\"PyTorch is installed at: {torch_location}\")\n",
    "        \n",
    "        # Try to get package info\n",
    "        try:\n",
    "            import pkg_resources\n",
    "            torch_pkg = pkg_resources.get_distribution(\"torch\")\n",
    "            print(f\"PyTorch package version: {torch_pkg.version}\")\n",
    "            print(f\"Package location: {torch_pkg.location}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not get package info: {e}\")\n",
    "            \n",
    "        # Try to determine if this was installed with CUDA support\n",
    "        if hasattr(torch.version, 'cuda') and torch.version.cuda:\n",
    "            print(f\"This appears to be a CUDA-enabled build of PyTorch\")\n",
    "        else:\n",
    "            print(f\"This appears to be a CPU-only build of PyTorch\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"PyTorch is not installed\")\n",
    "\n",
    "print(\"Checking PyTorch installation details...\")\n",
    "check_install_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ GPU Power Settings and Optimus Diagnosis\n",
    "\n",
    "Let's check if this might be an issue with laptop hybrid graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your system has hybrid graphics (AMD + NVIDIA)\n",
      "This is common in laptops and can cause issues with GPU recognition unless configured correctly.\n",
      "\n",
      "Possible issues:\n",
      "1. Your laptop might be in power-saving mode, which disables the NVIDIA GPU\n",
      "2. The NVIDIA GPU might not be set as the preferred graphics processor for Python\n",
      "3. NVIDIA Optimus technology might be preventing direct access to the GPU\n"
     ]
    }
   ],
   "source": [
    "def check_hybrid_graphics():\n",
    "    # Check if this is a laptop with dual graphics\n",
    "    if platform.system() == \"Windows\" and len(nvidia_gpus) > 0 and len(amd_gpus) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "has_hybrid = check_hybrid_graphics()\n",
    "\n",
    "if has_hybrid:\n",
    "    print(\"Your system has hybrid graphics (AMD + NVIDIA)\")\n",
    "    print(\"This is common in laptops and can cause issues with GPU recognition unless configured correctly.\")\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"1. Your laptop might be in power-saving mode, which disables the NVIDIA GPU\")\n",
    "    print(\"2. The NVIDIA GPU might not be set as the preferred graphics processor for Python\")\n",
    "    print(\"3. NVIDIA Optimus technology might be preventing direct access to the GPU\")\n",
    "else:\n",
    "    print(\"Your system doesn't appear to have hybrid graphics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Path Forward: What To Do Next\n",
    "\n",
    "Based on the diagnostics, here are the recommended steps to get your GPU working with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                     DIAGNOSIS AND SOLUTION RECOMMENDATIONS                     \n",
      "================================================================================\n",
      "\n",
      "Your PyTorch installation appears to have GPU support, but there may be another issue.\n",
      "Please check the error messages above for more specific information.\n"
     ]
    }
   ],
   "source": [
    "def recommend_solution():\n",
    "    has_nvidia = len(nvidia_gpus) > 0\n",
    "    has_cuda_build = hasattr(torch.version, 'cuda') and torch.version.cuda is not None\n",
    "    cuda_working = torch.cuda.is_available() if 'torch' in sys.modules else False\n",
    "    \n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"DIAGNOSIS AND SOLUTION RECOMMENDATIONS\".center(80))\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    if not has_nvidia:\n",
    "        print(\"\\nIssue: No NVIDIA GPU detected in the system\")\n",
    "        print(\"Solution: If you believe you have an NVIDIA GPU, check if it's properly installed and recognized by Windows.\")\n",
    "        return\n",
    "    \n",
    "    if not has_cuda_build:\n",
    "        print(\"\\nIssue: Your PyTorch installation is CPU-only (doesn't include CUDA support)\")\n",
    "        print(\"\\nSolution: Reinstall PyTorch with CUDA support.\")\n",
    "        print(\"\\nUsing uv:\")\n",
    "        print(\"uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "        print(\"\\nOr using pip:\")\n",
    "        print(\"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "        print(\"\\nAfter installation, restart your kernel and rerun this notebook.\")\n",
    "        return\n",
    "    \n",
    "    if has_cuda_build and not cuda_working:\n",
    "        print(\"\\nIssue: PyTorch has CUDA support but can't access the GPU at runtime\")\n",
    "        \n",
    "        if has_hybrid:\n",
    "            print(\"\\nLikely cause: Hybrid graphics configuration issue (NVIDIA Optimus)\")\n",
    "            print(\"\\nSolutions to try:\")\n",
    "            print(\"1. Set your laptop to high-performance mode in Windows power settings\")\n",
    "            print(\"2. Open NVIDIA Control Panel > Manage 3D Settings > Program Settings\")\n",
    "            print(\"   - Add python.exe and jupyter.exe to the list\")\n",
    "            print(\"   - Set them to use the 'High-performance NVIDIA processor'\")\n",
    "            print(\"3. If available, check your laptop's BIOS settings for graphics options\")\n",
    "            print(\"   - Some laptops allow disabling hybrid graphics or setting a preference\")\n",
    "            print(\"\\nAlternatively, try a different approach:\")\n",
    "            print(\"1. Uninstall PyTorch: uv pip uninstall torch torchvision torchaudio\")\n",
    "            print(\"2. Download the wheel files directly from https://download.pytorch.org/whl/cu121/torch/\")\n",
    "            print(\"3. Install them using: uv pip install <downloaded-wheel-file>\")\n",
    "        else:\n",
    "            print(\"\\nLikely causes:\")\n",
    "            print(\"1. Incompatible CUDA version: The CUDA version in PyTorch doesn't match your drivers\")\n",
    "            print(\"2. Missing CUDA toolkit or incorrect environment variables\")\n",
    "            print(\"\\nSolutions to try:\")\n",
    "            print(\"1. Update your NVIDIA drivers to the latest version\")\n",
    "            print(\"2. Reinstall PyTorch with a different CUDA version:\")\n",
    "            print(\"   - For CUDA 11.8: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "            print(\"   - For CUDA 12.1: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nYour PyTorch installation appears to have GPU support, but there may be another issue.\")\n",
    "    print(\"Please check the error messages above for more specific information.\")\n",
    "\n",
    "# Run the recommendation engine\n",
    "try:\n",
    "    recommend_solution()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating recommendations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Additional Information for Debugging\n",
    "\n",
    "If you're still having issues, let's collect some more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting detailed system information for debugging...\n",
      "\n",
      "Python executable: c:\\Users\\fire\\Documents\\Code\\python\\ai\\.venv\\Scripts\\python.exe\n",
      "Python version: 3.12.9 (main, Feb 12 2025, 14:52:31) [MSC v.1942 64 bit (AMD64)]\n",
      "Python path: ['C:\\\\Users\\\\fire\\\\AppData\\\\Roaming\\\\uv\\\\python\\\\cpython-3.12.9-windows-x86_64-none\\\\python312.zip', 'C:\\\\Users\\\\fire\\\\AppData\\\\Roaming\\\\uv\\\\python\\\\cpython-3.12.9-windows-x86_64-none\\\\DLLs', 'C:\\\\Users\\\\fire\\\\AppData\\\\Roaming\\\\uv\\\\python\\\\cpython-3.12.9-windows-x86_64-none\\\\Lib', 'C:\\\\Users\\\\fire\\\\AppData\\\\Roaming\\\\uv\\\\python\\\\cpython-3.12.9-windows-x86_64-none', 'c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv', '', 'c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor']\n",
      "\n",
      "Installed packages:\n",
      "Error getting pip list: Command '['c:\\\\Users\\\\fire\\\\Documents\\\\Code\\\\python\\\\ai\\\\.venv\\\\Scripts\\\\python.exe', '-m', 'pip', 'list']' returned non-zero exit status 1.\n",
      "\n",
      "CUDA-related environment variables:\n",
      "HOMEPATH: \\Users\\fire\n",
      "PATH: c:\\Users\\fire\\Documents\\Code\\python\\ai\\.venv\\Scripts;C:\\Users\\fire\\Documents\\Code\\python\\ai\\.venv\\Scripts;C:\\Program Files\\WindowsApps\\Microsoft.PowerShell_7.5.0.0_x64__8wekyb3d8bbwe;c:\\Users\\fire\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files\\Alacritty\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\Program Files\\dotnet\\;C:\\Program Files\\GitHub CLI\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\nodejs\\;C:\\Program Files\\Neovim\\bin;;C:\\Program Files\\Microsoft VS Code Insiders\\bin;C:\\Program Files\\starship\\bin\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Users\\fire\\miniforge3;C:\\Users\\fire\\miniforge3\\Library\\mingw-w64\\bin;C:\\Users\\fire\\miniforge3\\Library\\usr\\bin;C:\\Users\\fire\\miniforge3\\Library\\bin;C:\\Users\\fire\\miniforge3\\Scripts;C:\\Users\\fire\\.local\\bin;C:\\Users\\fire\\AppData\\Local\\pnpm;C:\\Users\\fire\\AppData\\Local\\pnpm;C:\\Users\\fire\\.cargo\\bin;C:\\Users\\fire\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\fire\\AppData\\Local\\Programs\\oh-my-posh\\bin;C:\\Users\\fire\\AppData\\Local\\gitkraken\\bin;C:\\Users\\fire\\AppData\\Local\\Programs\\Microsoft VS Code Insiders\\bin;C:\\Users\\fire\\AppData\\Local\\bin\\NASM;C:\\Users\\fire\\AppData\\Local\\Microsoft\\WinGet\\Links;C:\\Users\\fire\\.bun\\bin;C:\\Users\\fire\\.deno\\bin;C:\\Users\\fire\\AppData\\Local\\JetBrains\\Toolbox\\scripts;C:\\Users\\fire\\AppData\\Local\\Programs\\Ollama;C:\\Users\\fire\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.43.34808\\bin\\Hostx86\\x64\n",
      "PATHEXT: .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.CPL\n",
      "POSH_THEMES_PATH: C:\\Users\\fire\\AppData\\Local\\Programs\\oh-my-posh\\themes\n",
      "PSMODULEPATH: C:\\Users\\fire\\Documents\\PowerShell\\Modules;C:\\Program Files\\PowerShell\\Modules;c:\\program files\\windowsapps\\microsoft.powershell_7.5.0.0_x64__8wekyb3d8bbwe\\Modules;C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\n",
      "VSCODE_CODE_CACHE_PATH: C:\\Users\\fire\\AppData\\Roaming\\Code - Insiders\\CachedData\\3ea047c09e86b75b33ea8c84a351efd7d3899558\n",
      "_OLD_VIRTUAL_PATH: C:\\Program Files\\WindowsApps\\Microsoft.PowerShell_7.5.0.0_x64__8wekyb3d8bbwe;c:\\Users\\fire\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files\\Alacritty\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\Program Files\\dotnet\\;C:\\Program Files\\GitHub CLI\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\nodejs\\;C:\\Program Files\\Neovim\\bin;;C:\\Program Files\\Microsoft VS Code Insiders\\bin;C:\\Program Files\\starship\\bin\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Users\\fire\\miniforge3;C:\\Users\\fire\\miniforge3\\Library\\mingw-w64\\bin;C:\\Users\\fire\\miniforge3\\Library\\usr\\bin;C:\\Users\\fire\\miniforge3\\Library\\bin;C:\\Users\\fire\\miniforge3\\Scripts;C:\\Users\\fire\\.local\\bin;C:\\Users\\fire\\AppData\\Local\\pnpm;C:\\Users\\fire\\AppData\\Local\\pnpm;C:\\Users\\fire\\.cargo\\bin;C:\\Users\\fire\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\fire\\AppData\\Local\\Programs\\oh-my-posh\\bin;C:\\Users\\fire\\AppData\\Local\\gitkraken\\bin;C:\\Users\\fire\\AppData\\Local\\Programs\\Microsoft VS Code Insiders\\bin;C:\\Users\\fire\\AppData\\Local\\bin\\NASM;C:\\Users\\fire\\AppData\\Local\\Microsoft\\WinGet\\Links;C:\\Users\\fire\\.bun\\bin;C:\\Users\\fire\\.deno\\bin;C:\\Users\\fire\\AppData\\Local\\JetBrains\\Toolbox\\scripts;C:\\Users\\fire\\AppData\\Local\\Programs\\Ollama;C:\\Users\\fire\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.43.34808\\bin\\Hostx86\\x64\n",
      "CUDA_MODULE_LOADING: LAZY\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting detailed system information for debugging...\")\n",
    "\n",
    "# Python environment\n",
    "print(f\"\\nPython executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "# Try to get pip list\n",
    "try:\n",
    "    print(\"\\nInstalled packages:\")\n",
    "    pip_list = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"list\"]).decode()\n",
    "    print(pip_list)\n",
    "except Exception as e:\n",
    "    print(f\"Error getting pip list: {e}\")\n",
    "    \n",
    "# Environment variables related to CUDA\n",
    "print(\"\\nCUDA-related environment variables:\")\n",
    "for key, value in os.environ.items():\n",
    "    if \"CUDA\" in key or \"NVIDIA\" in key or \"GPU\" in key or \"PATH\" in key:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Test PyTorch CPU Performance\n",
    "\n",
    "Until we get your GPU working, let's see how your CPU performs with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PyTorch CPU performance...\n",
      "\n",
      "Matrix multiplication with size 1000x1000\n",
      "Time taken: 0.0050 seconds\n",
      "\n",
      "Matrix multiplication with size 2000x2000\n",
      "Time taken: 0.0439 seconds\n",
      "\n",
      "Matrix multiplication with size 4000x4000\n",
      "Time taken: 0.3385 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def test_cpu_performance():\n",
    "    print(\"Testing PyTorch CPU performance...\")\n",
    "    \n",
    "    # Test matrix multiplication with different sizes\n",
    "    sizes = [1000, 2000, 4000]\n",
    "    \n",
    "    for size in sizes:\n",
    "        print(f\"\\nMatrix multiplication with size {size}x{size}\")\n",
    "        \n",
    "        # Create random matrices\n",
    "        a = torch.randn(size, size)\n",
    "        b = torch.randn(size, size)\n",
    "        \n",
    "        # Warm-up run\n",
    "        _ = torch.matmul(a, b)\n",
    "        \n",
    "        # Timed run\n",
    "        start_time = time.time()\n",
    "        _ = torch.matmul(a, b)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "try:\n",
    "    test_cpu_performance()\n",
    "except Exception as e:\n",
    "    print(f\"Error during CPU performance test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Summary and Next Steps\n",
    "\n",
    "Here's a summary of what we found and what you should do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                          GPU TROUBLESHOOTING SUMMARY                           \n",
      "================================================================================\n",
      "\n",
      "System:\n",
      "  Operating System: Windows 11\n",
      "  Architecture: AMD64\n",
      "  Python: 3.12.9\n",
      "\n",
      "PyTorch:\n",
      "  Version: 2.5.1+cu121\n",
      "  CUDA Support: Yes\n",
      "  CUDA Version: 12.1\n",
      "  CUDA Available at Runtime: Yes\n",
      "\n",
      "GPU:\n",
      "  NVIDIA GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  AMD GPU: AMD Radeon 780M Graphics\n",
      "\n",
      "Diagnosis:\n",
      "  Everything appears to be working correctly\n",
      "\n",
      "Next Steps:\n",
      "  Your GPU setup appears to be working correctly with PyTorch\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_summary():\n",
    "    import torch\n",
    "    \n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"GPU TROUBLESHOOTING SUMMARY\".center(80))\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    print(\"\\nSystem:\")\n",
    "    print(f\"  Operating System: {platform.system()} {platform.release()}\")\n",
    "    print(f\"  Architecture: {platform.machine()}\")\n",
    "    print(f\"  Python: {sys.version.split()[0]}\")\n",
    "    \n",
    "    print(\"\\nPyTorch:\")\n",
    "    print(f\"  Version: {torch.__version__}\")\n",
    "    print(f\"  CUDA Support: {'Yes' if hasattr(torch.version, 'cuda') and torch.version.cuda else 'No'}\")\n",
    "    if hasattr(torch.version, 'cuda') and torch.version.cuda:\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  CUDA Available at Runtime: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    \n",
    "    print(\"\\nGPU:\")\n",
    "    if nvidia_gpus:\n",
    "        print(f\"  NVIDIA GPU: {nvidia_gpus[0]}\")\n",
    "    else:\n",
    "        print(\"  NVIDIA GPU: None detected\")\n",
    "    \n",
    "    if amd_gpus:\n",
    "        print(f\"  AMD GPU: {amd_gpus[0]}\")\n",
    "    \n",
    "    # Assess the situation\n",
    "    has_nvidia = len(nvidia_gpus) > 0\n",
    "    has_cuda_build = hasattr(torch.version, 'cuda') and torch.version.cuda is not None\n",
    "    cuda_working = torch.cuda.is_available()\n",
    "    \n",
    "    print(\"\\nDiagnosis:\")\n",
    "    if not has_nvidia:\n",
    "        print(\"  No NVIDIA GPU detected\")\n",
    "    elif not has_cuda_build:\n",
    "        print(\"  PyTorch doesn't have CUDA support\")\n",
    "    elif not cuda_working:\n",
    "        print(\"  PyTorch has CUDA support but can't access the GPU\")\n",
    "    else:\n",
    "        print(\"  Everything appears to be working correctly\")\n",
    "    \n",
    "    print(\"\\nNext Steps:\")\n",
    "    if has_nvidia and not has_cuda_build:\n",
    "        print(\"  1. Reinstall PyTorch with CUDA support using:\")\n",
    "        print(\"     uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    elif has_nvidia and has_cuda_build and not cuda_working:\n",
    "        print(\"  1. Check NVIDIA Control Panel settings (make sure Python uses the NVIDIA GPU)\")\n",
    "        print(\"  2. Make sure your laptop is in high-performance mode\")\n",
    "        print(\"  3. Try a different CUDA version of PyTorch (cu118 instead of cu121 or vice versa)\")\n",
    "    elif not has_nvidia:\n",
    "        print(\"  1. If you believe you have an NVIDIA GPU, check if it's properly installed\")\n",
    "    else:\n",
    "        print(\"  Your GPU setup appears to be working correctly with PyTorch\")\n",
    "        \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "\n",
    "try:\n",
    "    print_summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
