{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç GPU Troubleshooting and Diagnostics\n",
    "\n",
    "This notebook is designed to diagnose why your NVIDIA GPU isn't accessible through PyTorch and provide step-by-step solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ System and Installation Diagnostics\n",
    "\n",
    "First, let's check your current PyTorch installation and system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.9 (main, Feb 12 2025, 14:52:31) [MSC v.1942 64 bit (AMD64)]\n",
      "Platform: Windows-11-10.0.26100-SP0\n",
      "\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version (PyTorch): 12.4\n",
      "\n",
      "PyTorch build details:\n",
      "\n",
      "Is this a CPU-only build? No\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "# Check if PyTorch is installed and which version\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    print(\"\\nPyTorch version:\", torch.__version__)\n",
    "\n",
    "    # Check CUDA availability\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if hasattr(torch.version, \"cuda\"):\n",
    "        print(\"CUDA version (PyTorch):\", torch.version.cuda)\n",
    "    else:\n",
    "        print(\"CUDA version: Not found in PyTorch build\")\n",
    "\n",
    "    # Display PyTorch build information\n",
    "    print(\"\\nPyTorch build details:\")\n",
    "    build_details = torch.__config__.show()\n",
    "\n",
    "    # Check if this is a CPU-only build\n",
    "    print(\n",
    "        \"\\nIs this a CPU-only build?\",\n",
    "        \"Yes\"\n",
    "        if not hasattr(torch.version, \"cuda\") or torch.version.cuda is None\n",
    "        else \"No\",\n",
    "    )\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Check GPU Hardware\n",
    "\n",
    "Let's check which GPUs are physically present in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting GPUs...\n",
      "\n",
      "GPUs detected:\n",
      "  1. AMD Radeon 780M Graphics\n",
      "  2. NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "NVIDIA GPUs found:\n",
      "  1. NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "NVIDIA Driver Version: 32.0.15.7270\n",
      "\n",
      "AMD GPUs found:\n",
      "  1. AMD Radeon 780M Graphics\n"
     ]
    }
   ],
   "source": [
    "# Check for NVIDIA GPUs using Windows tools\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            gpu_info = (\n",
    "                subprocess.check_output(\n",
    "                    \"wmic path win32_VideoController get name\", shell=True\n",
    "                )\n",
    "                .decode()\n",
    "                .strip()\n",
    "                .split(\"\\n\")\n",
    "            )\n",
    "            gpu_info = [\n",
    "                line.strip()\n",
    "                for line in gpu_info\n",
    "                if line.strip() and line.strip() != \"Name\"\n",
    "            ]\n",
    "            return gpu_info\n",
    "        else:\n",
    "            return [\"Non-Windows platform - can't use wmic\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Error detecting GPUs: {e}\"]\n",
    "\n",
    "\n",
    "# Check NVIDIA driver\n",
    "def get_nvidia_driver_version():\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            driver_info = (\n",
    "                subprocess.check_output(\n",
    "                    \"wmic path win32_VideoController where \\\"name like '%NVIDIA%'\\\" get DriverVersion\",\n",
    "                    shell=True,\n",
    "                )\n",
    "                .decode()\n",
    "                .strip()\n",
    "                .split(\"\\n\")\n",
    "            )\n",
    "            driver_version = [\n",
    "                line.strip()\n",
    "                for line in driver_info\n",
    "                if line.strip() and line.strip() != \"DriverVersion\"\n",
    "            ]\n",
    "            return driver_version[0] if driver_version else \"Not found\"\n",
    "        else:\n",
    "            return \"Non-Windows platform\"\n",
    "    except Exception as e:\n",
    "        return f\"Error detecting NVIDIA driver: {e}\"\n",
    "\n",
    "\n",
    "# Run the diagnostics\n",
    "print(\"Detecting GPUs...\")\n",
    "gpus = get_gpu_info()\n",
    "print(\"\\nGPUs detected:\")\n",
    "for i, gpu in enumerate(gpus):\n",
    "    print(f\"  {i + 1}. {gpu}\")\n",
    "\n",
    "# Filter NVIDIA and AMD GPUs\n",
    "nvidia_gpus = [\n",
    "    gpu\n",
    "    for gpu in gpus\n",
    "    if \"NVIDIA\" in gpu or \"GeForce\" in gpu or \"RTX\" in gpu or \"GTX\" in gpu\n",
    "]\n",
    "amd_gpus = [gpu for gpu in gpus if \"AMD\" in gpu or \"Radeon\" in gpu]\n",
    "\n",
    "if nvidia_gpus:\n",
    "    print(\"\\nNVIDIA GPUs found:\")\n",
    "    for i, gpu in enumerate(nvidia_gpus):\n",
    "        print(f\"  {i + 1}. {gpu}\")\n",
    "\n",
    "    # Get NVIDIA driver info\n",
    "    driver_version = get_nvidia_driver_version()\n",
    "    print(f\"\\nNVIDIA Driver Version: {driver_version}\")\n",
    "else:\n",
    "    print(\"\\nNo NVIDIA GPUs detected\")\n",
    "\n",
    "if amd_gpus:\n",
    "    print(\"\\nAMD GPUs found:\")\n",
    "    for i, gpu in enumerate(amd_gpus):\n",
    "        print(f\"  {i + 1}. {gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Diagnose PyTorch GPU Issues\n",
    "\n",
    "Let's determine why PyTorch isn't accessing your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pytorch_gpu_support():\n",
    "    try:\n",
    "        import torch\n",
    "\n",
    "        issues = []\n",
    "\n",
    "        # Check 1: Is PyTorch built with CUDA?\n",
    "        has_cuda_build = (\n",
    "            hasattr(torch.version, \"cuda\") and torch.version.cuda is not None\n",
    "        )\n",
    "        if not has_cuda_build:\n",
    "            issues.append(\"PyTorch installation doesn't include CUDA support\")\n",
    "\n",
    "        # Check 2: Is CUDA available at runtime?\n",
    "        if not torch.cuda.is_available():\n",
    "            if has_cuda_build:\n",
    "                issues.append(\n",
    "                    \"PyTorch has CUDA support, but can't access CUDA at runtime\"\n",
    "                )\n",
    "\n",
    "        # Check 3: Try to create a CUDA tensor\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                x = torch.ones(1, device=\"cuda\")\n",
    "                print(\"Successfully created a CUDA tensor!\")\n",
    "            except Exception as e:\n",
    "                issues.append(f\"Failed to create CUDA tensor: {e}\")\n",
    "\n",
    "        return issues\n",
    "    except ImportError:\n",
    "        return [\"PyTorch is not installed\"]\n",
    "\n",
    "\n",
    "# Check if CUDA is generally available on the system\n",
    "def check_system_cuda():\n",
    "    try:\n",
    "        # Try to run nvidia-smi command\n",
    "        result = subprocess.run(\n",
    "            [\"nvidia-smi\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=False,\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        else:\n",
    "            return False, result.stderr\n",
    "    except Exception as e:\n",
    "        return False, f\"Error running nvidia-smi: {e}\"\n",
    "\n",
    "\n",
    "# Run diagnostics\n",
    "issues = check_pytorch_gpu_support()\n",
    "if issues:\n",
    "    print(\"Issues detected with PyTorch GPU support:\")\n",
    "    for i, issue in enumerate(issues):\n",
    "        print(f\"  {i + 1}. {issue}\")\n",
    "else:\n",
    "    print(\"No issues detected with PyTorch GPU support\")\n",
    "\n",
    "# Check system CUDA\n",
    "print(\"\\nChecking if CUDA is generally available on your system...\")\n",
    "cuda_available, cuda_output = check_system_cuda()\n",
    "if cuda_available:\n",
    "    print(\"CUDA is available on your system! nvidia-smi output:\")\n",
    "    print(\"\\n\".join(cuda_output.split(\"\\n\")[:10]))  # Show first 10 lines only\n",
    "else:\n",
    "    print(f\"CUDA is not generally available on your system: {cuda_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify PyTorch Installation Source\n",
    "\n",
    "Let's check how PyTorch was installed to determine if it's the CUDA version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_install_source():\n",
    "    try:\n",
    "        # Get the location of PyTorch\n",
    "        import torch\n",
    "        import inspect\n",
    "\n",
    "        torch_location = inspect.getfile(torch)\n",
    "        print(f\"PyTorch is installed at: {torch_location}\")\n",
    "\n",
    "        # Try to get package info\n",
    "        try:\n",
    "            import pkg_resources\n",
    "\n",
    "            torch_pkg = pkg_resources.get_distribution(\"torch\")\n",
    "            print(f\"PyTorch package version: {torch_pkg.version}\")\n",
    "            print(f\"Package location: {torch_pkg.location}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not get package info: {e}\")\n",
    "\n",
    "        # Try to determine if this was installed with CUDA support\n",
    "        if hasattr(torch.version, \"cuda\") and torch.version.cuda:\n",
    "            print(f\"This appears to be a CUDA-enabled build of PyTorch\")\n",
    "        else:\n",
    "            print(f\"This appears to be a CPU-only build of PyTorch\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"PyTorch is not installed\")\n",
    "\n",
    "\n",
    "print(\"Checking PyTorch installation details...\")\n",
    "check_install_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ GPU Power Settings and Optimus Diagnosis\n",
    "\n",
    "Let's check if this might be an issue with laptop hybrid graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hybrid_graphics():\n",
    "    # Check if this is a laptop with dual graphics\n",
    "    if platform.system() == \"Windows\" and len(nvidia_gpus) > 0 and len(amd_gpus) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "has_hybrid = check_hybrid_graphics()\n",
    "\n",
    "if has_hybrid:\n",
    "    print(\"Your system has hybrid graphics (AMD + NVIDIA)\")\n",
    "    print(\n",
    "        \"This is common in laptops and can cause issues with GPU recognition unless configured correctly.\"\n",
    "    )\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"1. Your laptop might be in power-saving mode, which disables the NVIDIA GPU\")\n",
    "    print(\n",
    "        \"2. The NVIDIA GPU might not be set as the preferred graphics processor for Python\"\n",
    "    )\n",
    "    print(\"3. NVIDIA Optimus technology might be preventing direct access to the GPU\")\n",
    "else:\n",
    "    print(\"Your system doesn't appear to have hybrid graphics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Path Forward: What To Do Next\n",
    "\n",
    "Based on the diagnostics, here are the recommended steps to get your GPU working with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_solution():\n",
    "    has_nvidia = len(nvidia_gpus) > 0\n",
    "    has_cuda_build = hasattr(torch.version, \"cuda\") and torch.version.cuda is not None\n",
    "    cuda_working = torch.cuda.is_available() if \"torch\" in sys.modules else False\n",
    "\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"DIAGNOSIS AND SOLUTION RECOMMENDATIONS\".center(80))\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    if not has_nvidia:\n",
    "        print(\"\\nIssue: No NVIDIA GPU detected in the system\")\n",
    "        print(\n",
    "            \"Solution: If you believe you have an NVIDIA GPU, check if it's properly installed and recognized by Windows.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    if not has_cuda_build:\n",
    "        print(\n",
    "            \"\\nIssue: Your PyTorch installation is CPU-only (doesn't include CUDA support)\"\n",
    "        )\n",
    "        print(\"\\nSolution: Reinstall PyTorch with CUDA support.\")\n",
    "        print(\"\\nUsing uv:\")\n",
    "        print(\n",
    "            \"uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "        )\n",
    "        print(\"\\nOr using pip:\")\n",
    "        print(\n",
    "            \"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "        )\n",
    "        print(\"\\nAfter installation, restart your kernel and rerun this notebook.\")\n",
    "        return\n",
    "\n",
    "    if has_cuda_build and not cuda_working:\n",
    "        print(\"\\nIssue: PyTorch has CUDA support but can't access the GPU at runtime\")\n",
    "\n",
    "        if has_hybrid:\n",
    "            print(\n",
    "                \"\\nLikely cause: Hybrid graphics configuration issue (NVIDIA Optimus)\"\n",
    "            )\n",
    "            print(\"\\nSolutions to try:\")\n",
    "            print(\n",
    "                \"1. Set your laptop to high-performance mode in Windows power settings\"\n",
    "            )\n",
    "            print(\n",
    "                \"2. Open NVIDIA Control Panel > Manage 3D Settings > Program Settings\"\n",
    "            )\n",
    "            print(\"   - Add python.exe and jupyter.exe to the list\")\n",
    "            print(\"   - Set them to use the 'High-performance NVIDIA processor'\")\n",
    "            print(\n",
    "                \"3. If available, check your laptop's BIOS settings for graphics options\"\n",
    "            )\n",
    "            print(\n",
    "                \"   - Some laptops allow disabling hybrid graphics or setting a preference\"\n",
    "            )\n",
    "            print(\"\\nAlternatively, try a different approach:\")\n",
    "            print(\"1. Uninstall PyTorch: uv pip uninstall torch torchvision torchaudio\")\n",
    "            print(\n",
    "                \"2. Download the wheel files directly from https://download.pytorch.org/whl/cu121/torch/\"\n",
    "            )\n",
    "            print(\"3. Install them using: uv pip install <downloaded-wheel-file>\")\n",
    "        else:\n",
    "            print(\"\\nLikely causes:\")\n",
    "            print(\n",
    "                \"1. Incompatible CUDA version: The CUDA version in PyTorch doesn't match your drivers\"\n",
    "            )\n",
    "            print(\"2. Missing CUDA toolkit or incorrect environment variables\")\n",
    "            print(\"\\nSolutions to try:\")\n",
    "            print(\"1. Update your NVIDIA drivers to the latest version\")\n",
    "            print(\"2. Reinstall PyTorch with a different CUDA version:\")\n",
    "            print(\n",
    "                \"   - For CUDA 11.8: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\"\n",
    "            )\n",
    "            print(\n",
    "                \"   - For CUDA 12.1: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "            )\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        \"\\nYour PyTorch installation appears to have GPU support, but there may be another issue.\"\n",
    "    )\n",
    "    print(\"Please check the error messages above for more specific information.\")\n",
    "\n",
    "\n",
    "# Run the recommendation engine\n",
    "try:\n",
    "    recommend_solution()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating recommendations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Additional Information for Debugging\n",
    "\n",
    "If you're still having issues, let's collect some more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collecting detailed system information for debugging...\")\n",
    "\n",
    "# Python environment\n",
    "print(f\"\\nPython executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "# Try to get pip list\n",
    "try:\n",
    "    print(\"\\nInstalled packages:\")\n",
    "    pip_list = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"list\"]).decode()\n",
    "    print(pip_list)\n",
    "except Exception as e:\n",
    "    print(f\"Error getting pip list: {e}\")\n",
    "\n",
    "# Environment variables related to CUDA\n",
    "print(\"\\nCUDA-related environment variables:\")\n",
    "for key, value in os.environ.items():\n",
    "    if \"CUDA\" in key or \"NVIDIA\" in key or \"GPU\" in key or \"PATH\" in key:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test PyTorch CPU Performance\n",
    "\n",
    "Until we get your GPU working, let's see how your CPU performs with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def test_cpu_performance():\n",
    "    print(\"Testing PyTorch CPU performance...\")\n",
    "\n",
    "    # Test matrix multiplication with different sizes\n",
    "    sizes = [1000, 2000, 4000]\n",
    "\n",
    "    for size in sizes:\n",
    "        print(f\"\\nMatrix multiplication with size {size}x{size}\")\n",
    "\n",
    "        # Create random matrices\n",
    "        a = torch.randn(size, size)\n",
    "        b = torch.randn(size, size)\n",
    "\n",
    "        # Warm-up run\n",
    "        _ = torch.matmul(a, b)\n",
    "\n",
    "        # Timed run\n",
    "        start_time = time.time()\n",
    "        _ = torch.matmul(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "try:\n",
    "    test_cpu_performance()\n",
    "except Exception as e:\n",
    "    print(f\"Error during CPU performance test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Summary and Next Steps\n",
    "\n",
    "Here's a summary of what we found and what you should do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary():\n",
    "    import torch\n",
    "\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"GPU TROUBLESHOOTING SUMMARY\".center(80))\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    print(\"\\nSystem:\")\n",
    "    print(f\"  Operating System: {platform.system()} {platform.release()}\")\n",
    "    print(f\"  Architecture: {platform.machine()}\")\n",
    "    print(f\"  Python: {sys.version.split()[0]}\")\n",
    "\n",
    "    print(\"\\nPyTorch:\")\n",
    "    print(f\"  Version: {torch.__version__}\")\n",
    "    print(\n",
    "        f\"  CUDA Support: {'Yes' if hasattr(torch.version, 'cuda') and torch.version.cuda else 'No'}\"\n",
    "    )\n",
    "    if hasattr(torch.version, \"cuda\") and torch.version.cuda:\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(\n",
    "        f\"  CUDA Available at Runtime: {'Yes' if torch.cuda.is_available() else 'No'}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nGPU:\")\n",
    "    if nvidia_gpus:\n",
    "        print(f\"  NVIDIA GPU: {nvidia_gpus[0]}\")\n",
    "    else:\n",
    "        print(\"  NVIDIA GPU: None detected\")\n",
    "\n",
    "    if amd_gpus:\n",
    "        print(f\"  AMD GPU: {amd_gpus[0]}\")\n",
    "\n",
    "    # Assess the situation\n",
    "    has_nvidia = len(nvidia_gpus) > 0\n",
    "    has_cuda_build = hasattr(torch.version, \"cuda\") and torch.version.cuda is not None\n",
    "    cuda_working = torch.cuda.is_available()\n",
    "\n",
    "    print(\"\\nDiagnosis:\")\n",
    "    if not has_nvidia:\n",
    "        print(\"  No NVIDIA GPU detected\")\n",
    "    elif not has_cuda_build:\n",
    "        print(\"  PyTorch doesn't have CUDA support\")\n",
    "    elif not cuda_working:\n",
    "        print(\"  PyTorch has CUDA support but can't access the GPU\")\n",
    "    else:\n",
    "        print(\"  Everything appears to be working correctly\")\n",
    "\n",
    "    print(\"\\nNext Steps:\")\n",
    "    if has_nvidia and not has_cuda_build:\n",
    "        print(\"  1. Reinstall PyTorch with CUDA support using:\")\n",
    "        print(\n",
    "            \"     uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "        )\n",
    "    elif has_nvidia and has_cuda_build and not cuda_working:\n",
    "        print(\n",
    "            \"  1. Check NVIDIA Control Panel settings (make sure Python uses the NVIDIA GPU)\"\n",
    "        )\n",
    "        print(\"  2. Make sure your laptop is in high-performance mode\")\n",
    "        print(\n",
    "            \"  3. Try a different CUDA version of PyTorch (cu118 instead of cu121 or vice versa)\"\n",
    "        )\n",
    "    elif not has_nvidia:\n",
    "        print(\n",
    "            \"  1. If you believe you have an NVIDIA GPU, check if it's properly installed\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"  Your GPU setup appears to be working correctly with PyTorch\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    print_summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
