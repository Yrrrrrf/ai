{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç GPU Troubleshooting and Diagnostics\n",
    "\n",
    "This notebook is designed to diagnose why your NVIDIA GPU isn't accessible through PyTorch and provide step-by-step solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ System and Installation Diagnostics\n",
    "\n",
    "First, let's check your current PyTorch installation and system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.11 (main, Jul 11 2025, 22:43:48) [Clang 20.1.4 ]\n",
      "Platform: Linux-6.12.48-x86_64-with-glibc2.40\n",
      "\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version (PyTorch): 12.4\n",
      "\n",
      "PyTorch build details:\n",
      "\n",
      "Is this a CPU-only build? No\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "# Check if PyTorch is installed and which version\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    print(\"\\nPyTorch version:\", torch.__version__)\n",
    "\n",
    "    # Check CUDA availability\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if hasattr(torch.version, \"cuda\"):\n",
    "        print(\"CUDA version (PyTorch):\", torch.version.cuda)\n",
    "    else:\n",
    "        print(\"CUDA version: Not found in PyTorch build\")\n",
    "\n",
    "    # Display PyTorch build information\n",
    "    print(\"\\nPyTorch build details:\")\n",
    "    build_details = torch.__config__.show()\n",
    "\n",
    "    # Check if this is a CPU-only build\n",
    "    print(\n",
    "        \"\\nIs this a CPU-only build?\",\n",
    "        \"Yes\"\n",
    "        if not hasattr(torch.version, \"cuda\") or torch.version.cuda is None\n",
    "        else \"No\",\n",
    "    )\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Check GPU Hardware\n",
    "\n",
    "Let's check which GPUs are physically present in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting GPUs...\n",
      "\n",
      "GPUs detected:\n",
      "  1. Non-Windows platform - can't use wmic\n",
      "\n",
      "No NVIDIA GPUs detected\n"
     ]
    }
   ],
   "source": [
    "# Check for NVIDIA GPUs using Windows tools\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            gpu_info = (\n",
    "                subprocess.check_output(\n",
    "                    \"wmic path win32_VideoController get name\", shell=True\n",
    "                )\n",
    "                .decode()\n",
    "                .strip()\n",
    "                .split(\"\\n\")\n",
    "            )\n",
    "            gpu_info = [\n",
    "                line.strip()\n",
    "                for line in gpu_info\n",
    "                if line.strip() and line.strip() != \"Name\"\n",
    "            ]\n",
    "            return gpu_info\n",
    "        else:\n",
    "            return [\"Non-Windows platform - can't use wmic\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Error detecting GPUs: {e}\"]\n",
    "\n",
    "\n",
    "# Check NVIDIA driver\n",
    "def get_nvidia_driver_version():\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            driver_info = (\n",
    "                subprocess.check_output(\n",
    "                    \"wmic path win32_VideoController where \\\"name like '%NVIDIA%'\\\" get DriverVersion\",\n",
    "                    shell=True,\n",
    "                )\n",
    "                .decode()\n",
    "                .strip()\n",
    "                .split(\"\\n\")\n",
    "            )\n",
    "            driver_version = [\n",
    "                line.strip()\n",
    "                for line in driver_info\n",
    "                if line.strip() and line.strip() != \"DriverVersion\"\n",
    "            ]\n",
    "            return driver_version[0] if driver_version else \"Not found\"\n",
    "        else:\n",
    "            return \"Non-Windows platform\"\n",
    "    except Exception as e:\n",
    "        return f\"Error detecting NVIDIA driver: {e}\"\n",
    "\n",
    "\n",
    "# Run the diagnostics\n",
    "print(\"Detecting GPUs...\")\n",
    "gpus = get_gpu_info()\n",
    "print(\"\\nGPUs detected:\")\n",
    "for i, gpu in enumerate(gpus):\n",
    "    print(f\"  {i + 1}. {gpu}\")\n",
    "\n",
    "# Filter NVIDIA and AMD GPUs\n",
    "nvidia_gpus = [\n",
    "    gpu\n",
    "    for gpu in gpus\n",
    "    if \"NVIDIA\" in gpu or \"GeForce\" in gpu or \"RTX\" in gpu or \"GTX\" in gpu\n",
    "]\n",
    "amd_gpus = [gpu for gpu in gpus if \"AMD\" in gpu or \"Radeon\" in gpu]\n",
    "\n",
    "if nvidia_gpus:\n",
    "    print(\"\\nNVIDIA GPUs found:\")\n",
    "    for i, gpu in enumerate(nvidia_gpus):\n",
    "        print(f\"  {i + 1}. {gpu}\")\n",
    "\n",
    "    # Get NVIDIA driver info\n",
    "    driver_version = get_nvidia_driver_version()\n",
    "    print(f\"\\nNVIDIA Driver Version: {driver_version}\")\n",
    "else:\n",
    "    print(\"\\nNo NVIDIA GPUs detected\")\n",
    "\n",
    "if amd_gpus:\n",
    "    print(\"\\nAMD GPUs found:\")\n",
    "    for i, gpu in enumerate(amd_gpus):\n",
    "        print(f\"  {i + 1}. {gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Diagnose PyTorch GPU Issues\n",
    "\n",
    "Let's determine why PyTorch isn't accessing your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created a CUDA tensor!\n",
      "No issues detected with PyTorch GPU support\n",
      "\n",
      "Checking if CUDA is generally available on your system...\n",
      "CUDA is available on your system! nvidia-smi output:\n",
      "Thu Sep 25 12:30:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.153.02             Driver Version: 570.153.02     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P3              8W /   55W |     813MiB /   8188MiB |     16%      Default |\n"
     ]
    }
   ],
   "source": [
    "def check_pytorch_gpu_support():\n",
    "    try:\n",
    "        import torch\n",
    "\n",
    "        issues = []\n",
    "\n",
    "        # Check 1: Is PyTorch built with CUDA?\n",
    "        has_cuda_build = (\n",
    "            hasattr(torch.version, \"cuda\") and torch.version.cuda is not None\n",
    "        )\n",
    "        if not has_cuda_build:\n",
    "            issues.append(\"PyTorch installation doesn't include CUDA support\")\n",
    "\n",
    "        # Check 2: Is CUDA available at runtime?\n",
    "        if not torch.cuda.is_available():\n",
    "            if has_cuda_build:\n",
    "                issues.append(\n",
    "                    \"PyTorch has CUDA support, but can't access CUDA at runtime\"\n",
    "                )\n",
    "\n",
    "        # Check 3: Try to create a CUDA tensor\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                x = torch.ones(1, device=\"cuda\")\n",
    "                print(\"Successfully created a CUDA tensor!\")\n",
    "            except Exception as e:\n",
    "                issues.append(f\"Failed to create CUDA tensor: {e}\")\n",
    "\n",
    "        return issues\n",
    "    except ImportError:\n",
    "        return [\"PyTorch is not installed\"]\n",
    "\n",
    "\n",
    "# Check if CUDA is generally available on the system\n",
    "def check_system_cuda():\n",
    "    try:\n",
    "        # Try to run nvidia-smi command\n",
    "        result = subprocess.run(\n",
    "            [\"nvidia-smi\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            check=False,\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        else:\n",
    "            return False, result.stderr\n",
    "    except Exception as e:\n",
    "        return False, f\"Error running nvidia-smi: {e}\"\n",
    "\n",
    "\n",
    "# Run diagnostics\n",
    "issues = check_pytorch_gpu_support()\n",
    "if issues:\n",
    "    print(\"Issues detected with PyTorch GPU support:\")\n",
    "    for i, issue in enumerate(issues):\n",
    "        print(f\"  {i + 1}. {issue}\")\n",
    "else:\n",
    "    print(\"No issues detected with PyTorch GPU support\")\n",
    "\n",
    "# Check system CUDA\n",
    "print(\"\\nChecking if CUDA is generally available on your system...\")\n",
    "cuda_available, cuda_output = check_system_cuda()\n",
    "if cuda_available:\n",
    "    print(\"CUDA is available on your system! nvidia-smi output:\")\n",
    "    print(\"\\n\".join(cuda_output.split(\"\\n\")[:10]))  # Show first 10 lines only\n",
    "else:\n",
    "    print(f\"CUDA is not generally available on your system: {cuda_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify PyTorch Installation Source\n",
    "\n",
    "Let's check how PyTorch was installed to determine if it's the CUDA version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking PyTorch installation details...\n",
      "PyTorch is installed at: /home/yrrrrrf/docs/lab/ai/.venv/lib/python3.12/site-packages/torch/__init__.py\n",
      "PyTorch package version: 2.6.0+cu124\n",
      "Package location: /home/yrrrrrf/docs/lab/ai/.venv/lib/python3.12/site-packages\n",
      "This appears to be a CUDA-enabled build of PyTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5724/2696102152.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "def check_install_source():\n",
    "    try:\n",
    "        # Get the location of PyTorch\n",
    "        import torch\n",
    "        import inspect\n",
    "\n",
    "        torch_location = inspect.getfile(torch)\n",
    "        print(f\"PyTorch is installed at: {torch_location}\")\n",
    "\n",
    "        # Try to get package info\n",
    "        try:\n",
    "            import pkg_resources\n",
    "\n",
    "            torch_pkg = pkg_resources.get_distribution(\"torch\")\n",
    "            print(f\"PyTorch package version: {torch_pkg.version}\")\n",
    "            print(f\"Package location: {torch_pkg.location}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not get package info: {e}\")\n",
    "\n",
    "        # Try to determine if this was installed with CUDA support\n",
    "        if hasattr(torch.version, \"cuda\") and torch.version.cuda:\n",
    "            print(\"This appears to be a CUDA-enabled build of PyTorch\")\n",
    "        else:\n",
    "            print(\"This appears to be a CPU-only build of PyTorch\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"PyTorch is not installed\")\n",
    "\n",
    "\n",
    "print(\"Checking PyTorch installation details...\")\n",
    "check_install_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ GPU Power Settings and Optimus Diagnosis\n",
    "\n",
    "Let's check if this might be an issue with laptop hybrid graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your system doesn't appear to have hybrid graphics\n"
     ]
    }
   ],
   "source": [
    "def check_hybrid_graphics():\n",
    "    # Check if this is a laptop with dual graphics\n",
    "    if platform.system() == \"Windows\" and len(nvidia_gpus) > 0 and len(amd_gpus) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "has_hybrid = check_hybrid_graphics()\n",
    "\n",
    "if has_hybrid:\n",
    "    print(\"Your system has hybrid graphics (AMD + NVIDIA)\")\n",
    "    print(\n",
    "        \"This is common in laptops and can cause issues with GPU recognition unless configured correctly.\"\n",
    "    )\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"1. Your laptop might be in power-saving mode, which disables the NVIDIA GPU\")\n",
    "    print(\n",
    "        \"2. The NVIDIA GPU might not be set as the preferred graphics processor for Python\"\n",
    "    )\n",
    "    print(\"3. NVIDIA Optimus technology might be preventing direct access to the GPU\")\n",
    "else:\n",
    "    print(\"Your system doesn't appear to have hybrid graphics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Path Forward: What To Do Next\n",
    "\n",
    "Based on the diagnostics, here are the recommended steps to get your GPU working with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                     DIAGNOSIS AND SOLUTION RECOMMENDATIONS                     \n",
      "================================================================================\n",
      "\n",
      "Issue: No NVIDIA GPU detected in the system\n",
      "Solution: If you believe you have an NVIDIA GPU, check if it's properly installed and recognized by Windows.\n"
     ]
    }
   ],
   "source": [
    "def recommend_solution():\n",
    "    has_nvidia = len(nvidia_gpus) > 0\n",
    "    has_cuda_build = hasattr(torch.version, \"cuda\") and torch.version.cuda is not None\n",
    "    cuda_working = torch.cuda.is_available() if \"torch\" in sys.modules else False\n",
    "\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"DIAGNOSIS AND SOLUTION RECOMMENDATIONS\".center(80))\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    if not has_nvidia:\n",
    "        print(\"\\nIssue: No NVIDIA GPU detected in the system\")\n",
    "        print(\n",
    "            \"Solution: If you believe you have an NVIDIA GPU, check if it's properly installed and recognized by Windows.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    if not has_cuda_build:\n",
    "        print(\n",
    "            \"\\nIssue: Your PyTorch installation is CPU-only (doesn't include CUDA support)\"\n",
    "        )\n",
    "        print(\"\\nSolution: Reinstall PyTorch with CUDA support.\")\n",
    "        print(\"\\nUsing uv:\")\n",
    "        print(\n",
    "            \"uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "        )\n",
    "        print(\"\\nOr using pip:\")\n",
    "        print(\n",
    "            \"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "        )\n",
    "        print(\"\\nAfter installation, restart your kernel and rerun this notebook.\")\n",
    "        return\n",
    "\n",
    "    if has_cuda_build and not cuda_working:\n",
    "        print(\"\\nIssue: PyTorch has CUDA support but can't access the GPU at runtime\")\n",
    "\n",
    "        if has_hybrid:\n",
    "            print(\n",
    "                \"\\nLikely cause: Hybrid graphics configuration issue (NVIDIA Optimus)\"\n",
    "            )\n",
    "            print(\"\\nSolutions to try:\")\n",
    "            print(\n",
    "                \"1. Set your laptop to high-performance mode in Windows power settings\"\n",
    "            )\n",
    "            print(\n",
    "                \"2. Open NVIDIA Control Panel > Manage 3D Settings > Program Settings\"\n",
    "            )\n",
    "            print(\"   - Add python.exe and jupyter.exe to the list\")\n",
    "            print(\"   - Set them to use the 'High-performance NVIDIA processor'\")\n",
    "            print(\n",
    "                \"3. If available, check your laptop's BIOS settings for graphics options\"\n",
    "            )\n",
    "            print(\n",
    "                \"   - Some laptops allow disabling hybrid graphics or setting a preference\"\n",
    "            )\n",
    "            print(\"\\nAlternatively, try a different approach:\")\n",
    "            print(\"1. Uninstall PyTorch: uv pip uninstall torch torchvision torchaudio\")\n",
    "            print(\n",
    "                \"2. Download the wheel files directly from https://download.pytorch.org/whl/cu121/torch/\"\n",
    "            )\n",
    "            print(\"3. Install them using: uv pip install <downloaded-wheel-file>\")\n",
    "        else:\n",
    "            print(\"\\nLikely causes:\")\n",
    "            print(\n",
    "                \"1. Incompatible CUDA version: The CUDA version in PyTorch doesn't match your drivers\"\n",
    "            )\n",
    "            print(\"2. Missing CUDA toolkit or incorrect environment variables\")\n",
    "            print(\"\\nSolutions to try:\")\n",
    "            print(\"1. Update your NVIDIA drivers to the latest version\")\n",
    "            print(\"2. Reinstall PyTorch with a different CUDA version:\")\n",
    "            print(\n",
    "                \"   - For CUDA 11.8: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\"\n",
    "            )\n",
    "            print(\n",
    "                \"   - For CUDA 12.1: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "            )\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        \"\\nYour PyTorch installation appears to have GPU support, but there may be another issue.\"\n",
    "    )\n",
    "    print(\"Please check the error messages above for more specific information.\")\n",
    "\n",
    "\n",
    "# Run the recommendation engine\n",
    "try:\n",
    "    recommend_solution()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating recommendations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Additional Information for Debugging\n",
    "\n",
    "If you're still having issues, let's collect some more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting detailed system information for debugging...\n",
      "\n",
      "Python executable: /home/yrrrrrf/docs/lab/ai/.venv/bin/python\n",
      "Python version: 3.12.11 (main, Jul 11 2025, 22:43:48) [Clang 20.1.4 ]\n",
      "Python path: ['/home/yrrrrrf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python312.zip', '/home/yrrrrrf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12', '/home/yrrrrrf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/lib-dynload', '', '/home/yrrrrrf/docs/lab/ai/.venv/lib/python3.12/site-packages', '/home/yrrrrrf/docs/lab/ai/.venv/lib/python3.12/site-packages/setuptools/_vendor']\n",
      "\n",
      "Installed packages:\n",
      "Error getting pip list: Command '['/home/yrrrrrf/docs/lab/ai/.venv/bin/python', '-m', 'pip', 'list']' returned non-zero exit status 1.\n",
      "\n",
      "CUDA-related environment variables:\n",
      "NIX_LD_LIBRARY_PATH: /run/current-system/sw/share/nix-ld/lib\n",
      "PKG_CONFIG_PATH: /nix/store/az8d7l0d6qxj63mggb1w8ma37s1zyy7l-systemd-257.9-dev/lib/pkgconfig:/nix/store/284df5f5mq01h1wmsz9grrqzraa3r9vi-pkg-config-wrapper-0.29.2/lib/pkgconfig:/nix/store/l45smaks5jlwpz6sv9prwfwvx78p7ppq-alsa-lib-1.2.13/lib/pkgconfig:/nix/store/irmkdc4kl59sdhg5smvh0yac8h4lxgk7-glib-2.84.3-bin/lib/pkgconfig:/nix/store/45hwsgjwa6nxxb5rzz2kl68g3ikfprm6-libglvnd-1.7.0/lib/pkgconfig:/nix/store/g9hb2v6j1swy77w77ird840dq20xn136-libxkbcommon-1.8.1/lib/pkgconfig:/nix/store/bdnbmvvqsl7jw8kgnsgnf7scrxi42mis-sdl2-compat-2.32.56/lib/pkgconfig:/nix/store/n3d54sa58sfjci9arf20hkaffn6hc8wq-SDL2_gfx-1.0.4/lib/pkgconfig:/nix/store/bj9j254ml80xskmk3ngwbd45mr410y7r-SDL2_image-2.8.8/lib/pkgconfig:/nix/store/4049l0apcv6kh7nzh78n8ahk4icd61f2-SDL2_mixer-2.8.1/lib/pkgconfig:/nix/store/264gx9j467f9vnw8l4v9995a9clq4pb8-SDL2_ttf-2.24.0/lib/pkgconfig:/nix/store/rkz0izd95qp2lm8nd5vzwzghd5p04gdd-wayland-1.23.1/lib/pkgconfig:/nix/store/ayswhp8g569mhb0gbgxrvqw53hsq59mz-libX11-1.8.12/lib/pkgconfig:/nix/store/ck4f1lhzmbbrpharmzxnqzw4vfbgzkr7-libxcb-1.17.0/lib/pkgconfig:/nix/store/hkn7b9rdqky4m43mhk3pg1ind85yf8fv-libXcursor-1.2.3/lib/pkgconfig:/nix/store/phpmbvcjd7sppnbfg07g5v9xyjna9nbi-libXi-1.8.2/lib/pkgconfig:/nix/store/ksm28wdl5q73lrdmlvhvsr297lafcaj5-libXinerama-1.1.5/lib/pkgconfig:/nix/store/gvg4ibdx82jfy1alrh21pki3waxnfd88-libXrandr-1.5.4/lib/pkgconfig:/nix/store/yxg93fh1zyqybbybvq0jn5nm9jyz7bj7-fontconfig-2.16.0-bin/lib/pkgconfig:/nix/store/l1g7r8sgrc3djn0x51mpy8fz5wp3204d-freetype-2.13.3/lib/pkgconfig:/nix/store/4b0y2xmlmm7vwf7s2dh494mp5fl0wa2r-qtbase-6.9.2/lib/pkgconfig:/nix/store/bgqk36593sdn062np6bi913wv9xq9dxr-qtwayland-6.9.2/lib/pkgconfig:/nix/store/m5khpdpdl0qwlvnrwb9q6ib9m8x293hy-libjpeg-turbo-3.0.4-bin/lib/pkgconfig:/nix/store/gshwzbmpd5nj1k0k2wz1xck36z6ih1bm-libpng-apng-1.6.46/lib/pkgconfig:/nix/store/k89rwqkg52wiwdkjdnii28hzkbkygmaq-giflib-5.2.2/lib/pkgconfig\n",
      "XCURSOR_PATH: /home/yrrrrrf/.icons:/home/yrrrrrf/.local/share/icons:/home/yrrrrrf/.nix-profile/share/icons:/home/yrrrrrf/.nix-profile/share/pixmaps:/nix/profile/share/icons:/nix/profile/share/pixmaps:/home/yrrrrrf/.local/state/nix/profile/share/icons:/home/yrrrrrf/.local/state/nix/profile/share/pixmaps:/etc/profiles/per-user/yrrrrrf/share/icons:/etc/profiles/per-user/yrrrrrf/share/pixmaps:/nix/var/nix/profiles/default/share/icons:/nix/var/nix/profiles/default/share/pixmaps:/run/current-system/sw/share/icons:/run/current-system/sw/share/pixmaps\n",
      "NIX_PATH: nixpkgs=flake:nixpkgs:/nix/var/nix/profiles/per-user/root/channels\n",
      "VSCODE_CODE_CACHE_PATH: /home/yrrrrrf/.config/Code/CachedData/0f0d87fa9e96c856c5212fc86db137ac0d783365\n",
      "INFOPATH: /home/yrrrrrf/.nix-profile/info:/home/yrrrrrf/.nix-profile/share/info:/nix/profile/info:/nix/profile/share/info:/home/yrrrrrf/.local/state/nix/profile/info:/home/yrrrrrf/.local/state/nix/profile/share/info:/etc/profiles/per-user/yrrrrrf/info:/etc/profiles/per-user/yrrrrrf/share/info:/nix/var/nix/profiles/default/info:/nix/var/nix/profiles/default/share/info:/run/current-system/sw/info:/run/current-system/sw/share/info\n",
      "GTK_PATH: /home/yrrrrrf/.nix-profile/lib/gtk-2.0:/home/yrrrrrf/.nix-profile/lib/gtk-3.0:/home/yrrrrrf/.nix-profile/lib/gtk-4.0:/nix/profile/lib/gtk-2.0:/nix/profile/lib/gtk-3.0:/nix/profile/lib/gtk-4.0:/home/yrrrrrf/.local/state/nix/profile/lib/gtk-2.0:/home/yrrrrrf/.local/state/nix/profile/lib/gtk-3.0:/home/yrrrrrf/.local/state/nix/profile/lib/gtk-4.0:/etc/profiles/per-user/yrrrrrf/lib/gtk-2.0:/etc/profiles/per-user/yrrrrrf/lib/gtk-3.0:/etc/profiles/per-user/yrrrrrf/lib/gtk-4.0:/nix/var/nix/profiles/default/lib/gtk-2.0:/nix/var/nix/profiles/default/lib/gtk-3.0:/nix/var/nix/profiles/default/lib/gtk-4.0:/run/current-system/sw/lib/gtk-2.0:/run/current-system/sw/lib/gtk-3.0:/run/current-system/sw/lib/gtk-4.0\n",
      "QTWEBKIT_PLUGIN_PATH: /home/yrrrrrf/.nix-profile/lib/mozilla/plugins/:/nix/profile/lib/mozilla/plugins/:/home/yrrrrrf/.local/state/nix/profile/lib/mozilla/plugins/:/etc/profiles/per-user/yrrrrrf/lib/mozilla/plugins/:/nix/var/nix/profiles/default/lib/mozilla/plugins/:/run/current-system/sw/lib/mozilla/plugins/\n",
      "LD_LIBRARY_PATH: /nix/store/5j09pwqlw6xhsjklzx43c903ki3m8wab-libdbusmenu-glib-16.04.0/lib:/nix/store/az8d7l0d6qxj63mggb1w8ma37s1zyy7l-systemd-257.9-dev/lib:/nix/store/284df5f5mq01h1wmsz9grrqzraa3r9vi-pkg-config-wrapper-0.29.2/lib:/nix/store/l45smaks5jlwpz6sv9prwfwvx78p7ppq-alsa-lib-1.2.13/lib:/nix/store/svl12332fv5skndwxvsqw0w1i3xy4viv-glib-2.84.3/lib:/nix/store/45hwsgjwa6nxxb5rzz2kl68g3ikfprm6-libglvnd-1.7.0/lib:/nix/store/g9hb2v6j1swy77w77ird840dq20xn136-libxkbcommon-1.8.1/lib:/nix/store/bdnbmvvqsl7jw8kgnsgnf7scrxi42mis-sdl2-compat-2.32.56/lib:/nix/store/n3d54sa58sfjci9arf20hkaffn6hc8wq-SDL2_gfx-1.0.4/lib:/nix/store/bj9j254ml80xskmk3ngwbd45mr410y7r-SDL2_image-2.8.8/lib:/nix/store/4049l0apcv6kh7nzh78n8ahk4icd61f2-SDL2_mixer-2.8.1/lib:/nix/store/264gx9j467f9vnw8l4v9995a9clq4pb8-SDL2_ttf-2.24.0/lib:/nix/store/rkz0izd95qp2lm8nd5vzwzghd5p04gdd-wayland-1.23.1/lib:/nix/store/ayswhp8g569mhb0gbgxrvqw53hsq59mz-libX11-1.8.12/lib:/nix/store/ck4f1lhzmbbrpharmzxnqzw4vfbgzkr7-libxcb-1.17.0/lib:/nix/store/hkn7b9rdqky4m43mhk3pg1ind85yf8fv-libXcursor-1.2.3/lib:/nix/store/phpmbvcjd7sppnbfg07g5v9xyjna9nbi-libXi-1.8.2/lib:/nix/store/ksm28wdl5q73lrdmlvhvsr297lafcaj5-libXinerama-1.1.5/lib:/nix/store/gvg4ibdx82jfy1alrh21pki3waxnfd88-libXrandr-1.5.4/lib:/nix/store/7bjjr3xhgnncsnsygi13cxk43kmp54cg-fontconfig-2.16.0-lib/lib:/nix/store/l1g7r8sgrc3djn0x51mpy8fz5wp3204d-freetype-2.13.3/lib:/nix/store/4b0y2xmlmm7vwf7s2dh494mp5fl0wa2r-qtbase-6.9.2/lib:/nix/store/bgqk36593sdn062np6bi913wv9xq9dxr-qtwayland-6.9.2/lib:/nix/store/nkr0yygbdcs8i4s2y139xyrhnwqiim0f-libjpeg-turbo-3.0.4/lib:/nix/store/gshwzbmpd5nj1k0k2wz1xck36z6ih1bm-libpng-apng-1.6.46/lib:/nix/store/k89rwqkg52wiwdkjdnii28hzkbkygmaq-giflib-5.2.2/lib:/nix/store/5ip54pxvpiqq2qrkkwk1rd0a3vg7a3hn-cuda-merged-12.8/lib:/nix/store/dyy8948zw46ph4faw920g4yl6zhdli7g-cudnn-9.8.0.87-lib/lib:/nix/store/pm3zm3sbx180dj3jva40nal0z9ab3xvl-nvidia-x11-570.153.02-6.12.48/lib\n",
      "LIBEXEC_PATH: /home/yrrrrrf/.nix-profile/libexec:/nix/profile/libexec:/home/yrrrrrf/.local/state/nix/profile/libexec:/etc/profiles/per-user/yrrrrrf/libexec:/nix/var/nix/profiles/default/libexec:/run/current-system/sw/libexec\n",
      "PATH: /home/yrrrrrf/docs/lab/ai/.venv/bin:/nix/store/irmkdc4kl59sdhg5smvh0yac8h4lxgk7-glib-2.84.3-bin/bin:/home/yrrrrrf/.local/bin:/run/wrappers/bin:/home/yrrrrrf/.nix-profile/bin:/nix/profile/bin:/home/yrrrrrf/.local/state/nix/profile/bin:/etc/profiles/per-user/yrrrrrf/bin:/nix/var/nix/profiles/default/bin:/run/current-system/sw/bin:/nix/store/87zpmcmwvn48z4lbrfba74b312h22s6c-binutils-wrapper-2.44/bin:/nix/store/qp2sm63vxrwhx2gb7w1v6sbwcb7licdd-hyprland-qtutils-0.1.4/bin:/nix/store/cz994zlb77rlfqhp8vps5hzv6v4830rx-pciutils-3.13.0/bin:/nix/store/m53q460bmkxmnwk52jknjsw49kgc1y81-pkgconf-wrapper-2.4.3/bin\n",
      "JUPYTER_PATH: /home/yrrrrrf/.config/Code/User/globalStorage/ms-toolsai.jupyter/version-2025.8.0/jupyter\n",
      "CUDA_MODULE_LOADING: LAZY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yrrrrrf/docs/lab/ai/.venv/bin/python: No module named pip\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting detailed system information for debugging...\")\n",
    "\n",
    "# Python environment\n",
    "print(f\"\\nPython executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "# Try to get pip list\n",
    "try:\n",
    "    print(\"\\nInstalled packages:\")\n",
    "    pip_list = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"list\"]).decode()\n",
    "    print(pip_list)\n",
    "except Exception as e:\n",
    "    print(f\"Error getting pip list: {e}\")\n",
    "\n",
    "# Environment variables related to CUDA\n",
    "print(\"\\nCUDA-related environment variables:\")\n",
    "for key, value in os.environ.items():\n",
    "    if \"CUDA\" in key or \"NVIDIA\" in key or \"GPU\" in key or \"PATH\" in key:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test PyTorch CPU Performance\n",
    "\n",
    "Until we get your GPU working, let's see how your CPU performs with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PyTorch CPU performance...\n",
      "\n",
      "Matrix multiplication with size 1000x1000\n",
      "Time taken: 0.0136 seconds\n",
      "\n",
      "Matrix multiplication with size 2000x2000\n",
      "Time taken: 0.0499 seconds\n",
      "\n",
      "Matrix multiplication with size 4000x4000\n",
      "Time taken: 0.2180 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def test_cpu_performance():\n",
    "    print(\"Testing PyTorch CPU performance...\")\n",
    "\n",
    "    # Test matrix multiplication with different sizes\n",
    "    sizes = [1000, 2000, 4000]\n",
    "\n",
    "    for size in sizes:\n",
    "        print(f\"\\nMatrix multiplication with size {size}x{size}\")\n",
    "\n",
    "        # Create random matrices\n",
    "        a = torch.randn(size, size)\n",
    "        b = torch.randn(size, size)\n",
    "\n",
    "        # Warm-up run\n",
    "        _ = torch.matmul(a, b)\n",
    "\n",
    "        # Timed run\n",
    "        start_time = time.time()\n",
    "        _ = torch.matmul(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "try:\n",
    "    test_cpu_performance()\n",
    "except Exception as e:\n",
    "    print(f\"Error during CPU performance test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Summary and Next Steps\n",
    "\n",
    "Here's a summary of what we found and what you should do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                          GPU TROUBLESHOOTING SUMMARY                           \n",
      "================================================================================\n",
      "\n",
      "System:\n",
      "  Operating System: Linux 6.12.48\n",
      "  Architecture: x86_64\n",
      "  Python: 3.12.11\n",
      "\n",
      "PyTorch:\n",
      "  Version: 2.6.0+cu124\n",
      "  CUDA Support: Yes\n",
      "  CUDA Version: 12.4\n",
      "  CUDA Available at Runtime: Yes\n",
      "\n",
      "GPU:\n",
      "  NVIDIA GPU: None detected\n",
      "\n",
      "Diagnosis:\n",
      "  No NVIDIA GPU detected\n",
      "\n",
      "Next Steps:\n",
      "  1. If you believe you have an NVIDIA GPU, check if it's properly installed\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_summary():\n",
    "    import torch\n",
    "\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(\"GPU TROUBLESHOOTING SUMMARY\".center(80))\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    print(\"\\nSystem:\")\n",
    "    print(f\"  Operating System: {platform.system()} {platform.release()}\")\n",
    "    print(f\"  Architecture: {platform.machine()}\")\n",
    "    print(f\"  Python: {sys.version.split()[0]}\")\n",
    "\n",
    "    print(\"\\nPyTorch:\")\n",
    "    print(f\"  Version: {torch.__version__}\")\n",
    "    print(\n",
    "        f\"  CUDA Support: {'Yes' if hasattr(torch.version, 'cuda') and torch.version.cuda else 'No'}\"\n",
    "    )\n",
    "    if hasattr(torch.version, \"cuda\") and torch.version.cuda:\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(\n",
    "        f\"  CUDA Available at Runtime: {'Yes' if torch.cuda.is_available() else 'No'}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nGPU:\")\n",
    "    if nvidia_gpus:\n",
    "        print(f\"  NVIDIA GPU: {nvidia_gpus[0]}\")\n",
    "    else:\n",
    "        print(\"  NVIDIA GPU: None detected\")\n",
    "\n",
    "    if amd_gpus:\n",
    "        print(f\"  AMD GPU: {amd_gpus[0]}\")\n",
    "\n",
    "    # Assess the situation\n",
    "    has_nvidia = len(nvidia_gpus) > 0\n",
    "    has_cuda_build = hasattr(torch.version, \"cuda\") and torch.version.cuda is not None\n",
    "    cuda_working = torch.cuda.is_available()\n",
    "\n",
    "    print(\"\\nDiagnosis:\")\n",
    "    if not has_nvidia:\n",
    "        print(\"  No NVIDIA GPU detected\")\n",
    "    elif not has_cuda_build:\n",
    "        print(\"  PyTorch doesn't have CUDA support\")\n",
    "    elif not cuda_working:\n",
    "        print(\"  PyTorch has CUDA support but can't access the GPU\")\n",
    "    else:\n",
    "        print(\"  Everything appears to be working correctly\")\n",
    "\n",
    "    print(\"\\nNext Steps:\")\n",
    "    if has_nvidia and not has_cuda_build:\n",
    "        print(\"  1. Reinstall PyTorch with CUDA support using:\")\n",
    "        print(\n",
    "            \"     uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\"\n",
    "        )\n",
    "    elif has_nvidia and has_cuda_build and not cuda_working:\n",
    "        print(\n",
    "            \"  1. Check NVIDIA Control Panel settings (make sure Python uses the NVIDIA GPU)\"\n",
    "        )\n",
    "        print(\"  2. Make sure your laptop is in high-performance mode\")\n",
    "        print(\n",
    "            \"  3. Try a different CUDA version of PyTorch (cu118 instead of cu121 or vice versa)\"\n",
    "        )\n",
    "    elif not has_nvidia:\n",
    "        print(\n",
    "            \"  1. If you believe you have an NVIDIA GPU, check if it's properly installed\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"  Your GPU setup appears to be working correctly with PyTorch\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    print_summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
